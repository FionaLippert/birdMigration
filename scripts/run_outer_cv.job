#!/bin/bash

#SBATCH --partition=gpu_shared
#SBATCH --gres=gpu:1
#SBATCH --job-name=outerCV
#SBATCH --time=120:00:00
#SBATCH --output=slurm_output_%A_%a.out
#SBATCH --mail-type=BEGIN,END
#SBATCH --mail-user=f.lippert@uva.nl

# Note: use --partition=gpu_shared if not all GPUs on a node are needed, --gpus=2 would give 2 of them
# Note: use --partition=gpu_short for debugging


source activate birds

module load 2020
module load CUDA/11.0.2-GCC-9.3.0
module load cuDNN/8.0.3.33-gcccuda-2020a
module load NCCL/2.7.8-gcccuda-2020a

# read command line arguments
MODEL=$1
TEST_YEAR=$2

JOB_FILE=$HOME/birdMigration/scripts/run_outer_cv.job
CHECKPOINTDIR=$HOME/birdMigration/checkpoints/nested_cv_$MODEL/test_${TEST_YEAR}
HPARAM_FILE=$CHECKPOINTDIR/hp_grid_search/best_hp_settings.txt
OUTDIR=$CHECKPOINTDIR/final_evaluation

mkdir -p $OUTDIR
rsync $JOB_FILE $OUTDIR/


#Copy all necessary input files to scratch
mkdir "$TMPDIR"/data
cp -r $HOME/birdMigration/data/preprocessed "$TMPDIR"/data

cd $HOME/birdMigration/scripts

# run training and testing using best hyperparameter setting determined in inner CV 
srun python run_2.py root=$TMPDIR +sub_dir=final_$SLURM_ARRAY_TASK_ID \
	action=train+test \
	datasource.test_year=$TEST_YEAR \
	datasource.val_train_split=0 \
	job_id=$SLURM_ARRAY_TASK_ID \
	model=$MODEL \
	output_dir=$OUTDIR \
	$(cat $HPARAM_FILE)
